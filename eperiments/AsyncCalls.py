import os
import time
import json
import io
import openai
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

# ==========================================
# OPTIMIZACI√ìN 6: MODELO M√ÅS R√ÅPIDO
# ==========================================
def obtener_respuesta_chatgpt(prompt: str, model: str = "gpt-3.5-turbo-16k"):
    """Optimizaci√≥n: Usar el modelo m√°s r√°pido por defecto"""
    try:
        # Usar el modelo de ChatGPT correcto para 'gpt-3.5-turbo'
        if model == "gpt-3.5-turbo-16k":
            response = openai.ChatCompletion.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=500  # Aumentado para respuestas m√°s complejas
            )
            respuesta = response['choices'][0]['message']['content'].strip()
        else:
            # Mantener compatibilidad con el modelo de completaciones
            response = openai.Completion.create(
                model=model,
                prompt=prompt,
                temperature=0.7,
                max_tokens=500
            )
            respuesta = response['choices'][0]['text'].strip()
        
        return respuesta
    except Exception as e:
        return f"Error al obtener respuesta de ChatGPT: {e}"



# ==========================================
# FUNCION CON NUEVO CRITERIO DE SIMILITUD
# ==========================================
async def procesar_practica_con_prompt_unificado(cv_texto: str, practica: dict, puesto: str):
    global concurrent_tasks, max_concurrent_tasks
    # Incrementar contador concurrente de manera segura
    async with concurrent_tasks_lock:
        concurrent_tasks += 1
        if concurrent_tasks > max_concurrent_tasks:
            max_concurrent_tasks = concurrent_tasks
        print(f"[DEBUG] Tareas concurrentes activas: {concurrent_tasks} (m√°ximo: {max_concurrent_tasks})")
    """
    Optimizaci√≥n: Evaluar la compatibilidad con criterios m√°s detallados.
    Los criterios ahora est√°n m√°s alineados con la descripci√≥n de requisitos.
    """
    descripcion = practica['descripcion']
    title = practica['title']
    try:
        # Prompt unificado con los nuevos criterios de evaluaci√≥n
        prompt_unificado = f"""Analiza la compatibilidad entre este CV y esta pr√°ctica laboral seg√∫n los siguientes criterios:

1. Requisitos t√©cnicos (10%): Eval√∫a si el CV cumple con lo m√≠nimo que pide la empresa. Se consideran cosas como idiomas requeridos, herramientas t√©cnicas y nivel de estudios.
2. Similitud con el puesto (40%): Eval√∫a qu√© tan alineado est√° el perfil con el puesto solicitado. Mide si el estudiante tiene experiencia o formaci√≥n relevante, o si el puesto tiene relaci√≥n con su trayectoria o intereses.
3. Afinidad con el sector o tipo de empresa (15%): Eval√∫a si el estudiante tiene v√≠nculo con el sector de la empresa.
4. Similitud sem√°ntica general (25%): Compara todo el contenido del CV con la descripci√≥n de la vacante utilizando NLP o embeddings.
5. Juicio del sistema (10%): Un puntaje de ajuste basado en los criterios anteriores y eval√∫a si el perfil tiene sentido para esta pr√°ctica.

IMPORTANTE: Responde √öNICAMENTE con un JSON v√°lido con esta estructura exacta (sin texto adicional), SI O SI DEBE SER UN JSON PERFECTO ASI COMO TE DOY EL EJEMPLO, Generame como te di en el ejemplo, debe ser un json:

{{
  "requisitos_tecnicos": [n√∫mero entre 0-10],
  "similitud_puesto": [n√∫mero entre 0-40],
  "afinidad_sector": [n√∫mero entre 0-15],
  "similitud_semantica": [n√∫mero entre 0-25],
  "juicio_sistema": [n√∫mero entre 0-10],
  "justificacion_requisitos": "[justificaci√≥n de los requisitos t√©cnicos]",
  "justificacion_puesto": "[justificaci√≥n de la similitud con el puesto]",
  "justificacion_afinidad": "[justificaci√≥n de la afinidad con el sector]",
  "justificacion_semantica": "[justificaci√≥n sem√°ntica general]",
  "justificacion_juicio": "[justificaci√≥n del juicio final del sistema]"
}}

DATOS PARA ANALIZAR:

CV del candidato:
{cv_texto}

Descripci√≥n de la pr√°ctica:
{descripcion}

T√≠tulo de la pr√°ctica:
{title}

Puesto solicitado:
{puesto}

CRITERIOS:
- requisitos_tecnicos: Cumplimiento de requisitos b√°sicos de la pr√°ctica.
- similitud_puesto: Relaci√≥n entre el perfil y el puesto solicitado.
- afinidad_sector: Compatibilidad con el sector o tipo de empresa.
- similitud_semantica: Coincidencias sem√°nticas entre el CV y la vacante.
- juicio_sistema: Puntaje de ajuste general.
"""

        # Llamada as√≠ncrona directa a OpenAI
        client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo-16k",
            messages=[{"role": "user", "content": prompt_unificado}],
            temperature=0.7,
            max_tokens=500
        )
        respuesta_json = response.choices[0].message.content.strip()

        # Limpiar la respuesta en caso de que tenga texto extra no deseado
        respuesta_limpia = respuesta_json.strip()

        # Si la respuesta contiene texto no estructurado antes de un JSON, extraemos solo el JSON
        if respuesta_limpia.startswith('-'):
            start_index = respuesta_limpia.find("{")
            if start_index != -1:
                respuesta_limpia = respuesta_limpia[start_index:]
            else:
                raise ValueError("La respuesta no contiene un JSON v√°lido")

        # Intentamos asegurar que la respuesta sea un JSON v√°lido
        if respuesta_limpia.startswith("{") and respuesta_limpia.endswith("}"):
            try:
                # Intentar parsear la respuesta JSON
                resultado = json.loads(respuesta_limpia)

                # Verificar que todos los campos est√©n presentes en el resultado
                campos_requeridos = [
                    'requisitos_tecnicos', 'similitud_puesto', 'afinidad_sector',
                    'similitud_semantica', 'juicio_sistema', 'justificacion_requisitos',
                    'justificacion_puesto', 'justificacion_afinidad', 'justificacion_semantica',
                    'justificacion_juicio'
                ]

                # Verificar si los campos est√°n vac√≠os y dar justificaci√≥n detallada
                for campo in campos_requeridos:
                    if campo not in resultado or resultado[campo] in [None, '']:
                        print(f"Campo {campo} no presente o vac√≠o en la respuesta")
                        resultado[campo] = f"Campo '{campo}' no proporcionado por el modelo de ChatGPT."

                # Asegurar que los valores num√©ricos sean v√°lidos
                resultado['requisitos_tecnicos'] = max(0, min(10, float(resultado.get('requisitos_tecnicos', 0))))
                resultado['similitud_puesto'] = max(0, min(40, float(resultado.get('similitud_puesto', 0))))
                resultado['afinidad_sector'] = max(0, min(15, float(resultado.get('afinidad_sector', 0))))
                resultado['similitud_semantica'] = max(0, min(25, float(resultado.get('similitud_semantica', 0))))
                resultado['juicio_sistema'] = max(0, min(10, float(resultado.get('juicio_sistema', 0))))

            except json.JSONDecodeError as e:
                print(f"Error parsing JSON response: {e}")
                print(f"Raw response: {respuesta_limpia}")
                resultado = {
                    'requisitos_tecnicos': 0,
                    'similitud_puesto': 0,
                    'afinidad_sector': 0,
                    'similitud_semantica': 0,
                    'juicio_sistema': 0,
                    'justificacion_requisitos': "Error en la justificaci√≥n de los requisitos t√©cnicos.",
                    'justificacion_puesto': "Error en la justificaci√≥n del puesto.",
                    'justificacion_afinidad': "Error en la afinidad con el sector.",
                    'justificacion_semantica': "Error en la similitud sem√°ntica.",
                    'justificacion_juicio': "Error en el juicio del sistema."
                }
            except ValueError as e:
                print(f"Error al convertir los valores: {e}")
                resultado = {
                    'requisitos_tecnicos': 0,
                    'similitud_puesto': 0,
                    'afinidad_sector': 0,
                    'similitud_semantica': 0,
                    'juicio_sistema': 0,
                    'justificacion_requisitos': "Error al calcular los requisitos t√©cnicos.",
                    'justificacion_puesto': "Error al calcular la similitud con el puesto.",
                    'justificacion_afinidad': "Error al calcular la afinidad con el sector.",
                    'justificacion_semantica': "Error al calcular la similitud sem√°ntica.",
                    'justificacion_juicio': "Error al calcular el juicio final."
                }

        else:
            resultado = {
                'requisitos_tecnicos': 0,
                'similitud_puesto': 0,
                'afinidad_sector': 0,
                'similitud_semantica': 0,
                'juicio_sistema': 0,
                'justificacion_requisitos': "Respuesta inv√°lida o incompleta de ChatGPT.",
                'justificacion_puesto': "Respuesta inv√°lida o incompleta de ChatGPT.",
                'justificacion_afinidad': "Respuesta inv√°lida o incompleta de ChatGPT.",
                'justificacion_semantica': "Respuesta inv√°lida o incompleta de ChatGPT.",
                'justificacion_juicio': "Respuesta inv√°lida o incompleta de ChatGPT."
            }


        practica_con_resultados = practica.copy()
        practica_con_resultados.update(resultado)
        return practica_con_resultados

    except Exception as e:
        print(f"Error procesando pr√°ctica {practica.get('title', 'Unknown')}: {e}")
        return {"error": f"Error procesando pr√°ctica: {str(e)}"}
    finally:
        # Decrementar contador concurrente de manera segura
        async with concurrent_tasks_lock:
            concurrent_tasks -= 1
            print(f"[DEBUG] Tarea finalizada. Tareas concurrentes activas: {concurrent_tasks}")

# ==========================================
# OPTIMIZACI√ìN 2: PARALELIZACI√ìN COMPLETA
# ==========================================
async def comparar_practicas_con_cv(cv_texto: str, practicas: list, puesto: str, ):
    """
    Optimizaci√≥n: Procesar todas las pr√°cticas en paralelo
    Esto deber√≠a reducir el tiempo en un 50-70% adicional
    """
    # Limitar el n√∫mero de pr√°cticas si se especifica practicas_limite
    practicas_limite = 5  # Puedes establecer un l√≠mite aqu√≠ si es necesario
    if practicas_limite is not None:
        practicas = practicas[:practicas_limite]
    print(f"üöÄ Iniciando procesamiento optimizado de {len(practicas)} pr√°cticas...")
    start_time = time.time()

    # ANTES: Loop secuencial - una pr√°ctica por vez
    # AHORA: Todas las pr√°cticas en paralelo
    tasks = [
        procesar_practica_con_prompt_unificado(cv_texto, practica, puesto)
        for practica in practicas
    ]

    # Ejecutar todas las tareas en paralelo
    practicas_con_similitud = await asyncio.gather(*tasks, return_exceptions=True)
    
    resultados_validos = []
    for i, resultado in enumerate(practicas_con_similitud):
        if isinstance(resultado, dict):
            if 'error' in resultado:
                print(f"Error procesando pr√°ctica {i}: {resultado['error']}")
                practica_error = practicas[i].copy()
                practica_error.update({
                    'requisitos_tecnicos': 0,
                    'similitud_puesto': 0,
                    'afinidad_sector': 0,
                    'similitud_semantica': 0,
                    'juicio_sistema': 0,
                    'justificacion_requisitos': f"Error: {resultado['error']}",
                    'justificacion_puesto': f"Error: {resultado['error']}",
                    'justificacion_afinidad': f"Error: {resultado['error']}",
                    'justificacion_semantica': f"Error: {resultado['error']}",
                    'justificacion_juicio': f"Error: {resultado['error']}",
                    'similitud_total': 0.0
                })
                resultados_validos.append(practica_error)
            else:
                # Calcular similitud total sumando los 5 criterios si son num√©ricos
                try:
                    similitud_total = sum([
                        float(resultado.get('requisitos_tecnicos', 0)),
                        float(resultado.get('similitud_puesto', 0)),
                        float(resultado.get('afinidad_sector', 0)),
                        float(resultado.get('similitud_semantica', 0)),
                        float(resultado.get('juicio_sistema', 0))
                    ])
                except Exception as e:
                    print(f"Error calculando similitud_total en pr√°ctica {i}: {e}")
                    similitud_total = 0.0
                if isinstance(resultado, dict):
                    resultado['similitud_total'] = float(similitud_total)
                resultados_validos.append(resultado)
        else:
            # Si resultado es una excepci√≥n u otro tipo, registrar y crear error
            print(f"Error inesperado procesando pr√°ctica {i}: {resultado}")
            practica_error = practicas[i].copy()
            practica_error.update({
                'requisitos_tecnicos': 0,
                'similitud_puesto': 0,
                'afinidad_sector': 0,
                'similitud_semantica': 0,
                'juicio_sistema': 0,
                'justificacion_requisitos': f"Error inesperado: {resultado}",
                'justificacion_puesto': f"Error inesperado: {resultado}",
                'justificacion_afinidad': f"Error inesperado: {resultado}",
                'justificacion_semantica': f"Error inesperado: {resultado}",
                'justificacion_juicio': f"Error inesperado: {resultado}",
                'similitud_total': 0.0
            })
            resultados_validos.append(practica_error)

    # Ordenar por similitud_total (de mayor a menor)
    resultados_validos.sort(key=lambda x: x.get('similitud_total', 0), reverse=True)

    end_time = time.time()
    tiempo_total = end_time - start_time
    print(f"‚úÖ Procesamiento completado en {tiempo_total:.2f} segundos")
    print(f"üìä Promedio por pr√°ctica: {tiempo_total/len(practicas):.2f} segundos")
    global max_concurrent_tasks
    print(f"üö¶ M√°ximo de tareas concurrentes alcanzado: {max_concurrent_tasks}")
    # Reiniciar el m√°ximo para futuras llamadas
    max_concurrent_tasks = 0
    return resultados_validos

# ==============