from fastapi import FastAPI, Request, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from typing import AsyncGenerator
import json
import time
import asyncio
import logging
from datetime import datetime
from google.api_core.datetime_helpers import DatetimeWithNanoseconds
from dotenv import load_dotenv
import os

# Cargar variables de entorno desde .env
load_dotenv()

# Servicios
from services.job_service import (
    obtener_practicas,
    obtener_practicas_recientes,
    buscar_practicas_afines,
)
from services.user_service import (
    fetch_user_cv,
    save_cv as save_cv_service,
    update_cv as update_cv_service,
    get_user_cvs as get_user_cvs_service,
    upload_cv_to_database,
    delete_cv as delete_cv_service,
    get_cv_by_id,
)

# Configuraci√≥n para streaming puro (sin compresi√≥n)
STREAMING_CHUNK_SIZE = 3   # 1 pr√°ctica por chunk para m√°xima velocidad
STREAMING_ENABLED = True   # Flag para habilitar/deshabilitar streaming
USE_PURE_STREAMING = True  # Streaming sin compresi√≥n para latencia m√≠nima

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI()

# Configuraci√≥n de CORS (SIN GZipMiddleware para streaming puro)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)







def custom_json_serializer(obj):
    """Serializer personalizado para manejar tipos especiales de Firestore"""
    if isinstance(obj, DatetimeWithNanoseconds):
        return obj.isoformat()
    elif isinstance(obj, datetime):
        return obj.isoformat()
    raise TypeError(f"Object of type {type(obj)} is not JSON serializable")

async def generate_ndjson_streaming_practices(practicas: list, timing_stats: dict) -> AsyncGenerator[str, None]:
    """
    Generador as√≠ncrono que produce pr√°cticas en formato NDJSON streaming puro.
    
    NDJSON STREAMING: Cada pr√°ctica se env√≠a como una l√≠nea JSON separada.
    El frontend puede procesar cada l√≠nea inmediatamente sin esperar el JSON completo.
    
    Args:
        practicas: Lista de pr√°cticas a enviar
        timing_stats: Estad√≠sticas de tiempo del procesamiento
    
    Yields:
        str: L√≠neas NDJSON (una pr√°ctica por l√≠nea + metadata al final)
    """
    logger.info(f"üöÄ Iniciando NDJSON streaming de {len(practicas)} pr√°cticas")
    logger.info(f"üìù Formato: Una l√≠nea JSON por pr√°ctica")
    
    try:
        # Procesar pr√°cticas individualmente como l√≠neas NDJSON
        total_practicas = len(practicas)
        
        for practica_index, practica in enumerate(practicas):
            #logger.info(f"üì¶ Enviando pr√°ctica {practica_index + 1}/{total_practicas}")
            
            # Serializar pr√°ctica individual como l√≠nea JSON
            practica_json = json.dumps(practica, ensure_ascii=False, default=custom_json_serializer)
            
            # Enviar pr√°ctica como l√≠nea NDJSON (con salto de l√≠nea)
            yield f"{practica_json}\n"
            
            # Pausa m√≠nima para permitir procesamiento progresivo
            await asyncio.sleep(0.05)  # 50ms por pr√°ctica
        
        # Preparar metadata como √∫ltima l√≠nea NDJSON
        metadata = {
            "metadata": {
                "total_practicas_procesadas": len(practicas),
                "streaming": True,
                "chunk_size": STREAMING_CHUNK_SIZE,
                "timing_stats": timing_stats
            }
        }
        
        # Enviar metadata como √∫ltima l√≠nea NDJSON
        metadata_json = json.dumps(metadata, ensure_ascii=False, default=custom_json_serializer)
        yield f"{metadata_json}\n"
        
        logger.info(f"‚úÖ NDJSON streaming completado exitosamente - {len(practicas)} pr√°cticas + metadata enviadas")
        
    except Exception as e:
        logger.error(f"‚ùå Error durante NDJSON streaming: {e}")
        # Enviar error como l√≠nea NDJSON
        error_data = {
            "error": {
                "message": f"Error durante streaming: {str(e)}",
                "streaming": True,
                "format": "ndjson"
            }
        }
        error_json = json.dumps(error_data, ensure_ascii=False, default=custom_json_serializer)
        yield f"{error_json}\n"


@app.post("/match-practices")
async def match_practices(request: Request):
    """
    Endpoint optimizado para matching de pr√°cticas usando CV seleccionado
    Mejoras implementadas:
    - Usa cv_selected_id para consultar CV directamente en la base de datos
    - Si el CV tiene embeddings, los usa directamente (m√°s r√°pido)
    - Si no tiene embeddings, usa el campo data para generar embeddings
    - Soporte para compresi√≥n gzip bidireccional (request y response)
    - Medici√≥n detallada de tiempos por etapa
    """
    # Iniciar medici√≥n de tiempo total
    start_total = time.time()
    timing_stats = {}
    
    try:
        # Leer el body del request y parsear JSON
        body = await request.body()
        request_data = json.loads(body)
        
        print("------ Inputs ------ ")
        print("user_id: ", request_data.get("user_id", None))
        print("limit: ", request_data.get("limit", None))

        # Obtener el CV del usuario
        cv_user = await fetch_user_cv(request_data.get("user_id"))
        
        if not cv_user:
            raise HTTPException(status_code=404, detail="No se pudo obtener el CV del usuario. Verifique que el usuario existe y tiene un CV v√°lido.")

        if not cv_user.get("embeddings", None):
            # Retrocompatibilidad con versiones antiguas de la web
            # Este escenario casi nunca deberia ocurrir. Actualmente se maneja la generacion de embeddings desde que se sube el mismo CV. la unica posibilidad de que alguien tenga CVData pero no embeddings es que haya creado su cv previo a la release del dia 15 de agosto de 2025
            # Generar embeddings del CV desde datos estructurados usando extract_metadata_with_gemini
            print(f"‚è±Ô∏è  Paso 1: Generando embeddings del CV desde datos estructurados...")
            step1_start = time.time()
            from services.user_service import generate_cv_embeddings
            
            # Convertir cv_data a string usando json.dumps
            cv_text = json.dumps(cv_user.get("data", None), ensure_ascii=False)
            embeddings = await generate_cv_embeddings(cv_text)
            cv_user["embeddings"] = embeddings
            print(f"‚úÖ Paso 1 completado en {time.time() - step1_start:.2f} segundos (generaci√≥n desde datos estructurados)")
            #actualizar el cv en la base de datos
            await update_cv_service(cv_user.get("id"), cv_user)
        
        # Iniciar medici√≥n de b√∫squeda
        start_search = time.time()
        
        practicas_con_similitud = await buscar_practicas_afines(
            cv_embeddings=cv_user.get("embeddings", None),
            #devolver practicas solo mayores a 0%
            percentage_threshold= 0,
            #solo buscar pr√°cticas recientes (ultimos 5 dias)
            sinceDays=5,
        )
        
        timing_stats['search_matching'] = time.time() - start_search
        
        # 4. ETAPA: Preparaci√≥n de respuesta
        start_response_prep = time.time()
        
        # Calcular tiempo total hasta ahora
        timing_stats['total_processing'] = time.time() - start_total
        timing_stats['response_preparation'] = time.time() - start_response_prep
        timing_stats['total_time'] = time.time() - start_total
        
        print(f"\n‚è±Ô∏è ESTAD√çSTICAS DE TIEMPO:")
        print(f"   - B√∫squeda/Matching: {timing_stats['search_matching']:.4f}s")
        print(f"   - Preparaci√≥n respuesta: {timing_stats['response_preparation']:.4f}s")
        print(f"   - üéÜ TIEMPO TOTAL: {timing_stats['total_time']:.4f}s")
        
        # Usar siempre streaming puro sin compresi√≥n
        if STREAMING_ENABLED and len(practicas_con_similitud) > 0:
            print(f"üì° Usando STREAMING PURO - {len(practicas_con_similitud)} pr√°cticas")
            
            # Retornar StreamingResponse sin compresi√≥n
            return StreamingResponse(
                generate_ndjson_streaming_practices(practicas_con_similitud, timing_stats),
                media_type="application/x-ndjson",
                headers={
                    "Content-Type": "application/x-ndjson",
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive"
                }
            )
        else:
            print(f"üìÑ Usando respuesta JSON tradicional - {len(practicas_con_similitud)} pr√°cticas")
            
            # Respuesta tradicional sin compresi√≥n
            limit = request_data.get("limit", 100)
            response_data = {
                "practicas": practicas_con_similitud[:limit],
                "metadata": {
                    "total_practicas_procesadas": len(practicas_con_similitud),
                    "total_practicas_devueltas": min(limit, len(practicas_con_similitud)),
                    "streaming": False,
                    "timing_stats": timing_stats
                }
            }
            
            return response_data
            
    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="Error al parsear JSON")
    except Exception as e:
        print(f"‚ùå Error en match_practices: {e}")
        raise HTTPException(status_code=500, detail=f"Error interno: {str(e)}")


@app.get("/practicas")
def get_all_practicas():
    return obtener_practicas()

@app.get("/practicas-recientes")
def get_recent_practicas():
    return obtener_practicas_recientes()

@app.post("/upload-cv")
async def upload_cv(cv_pdf_file: UploadFile = File(...), user_id: str = Form(...)):
    """
    Endpoint para subir un CV a la base de datos del usuario.
    
    Proceso:
    1. Recibe el archivo PDF como multipart/form-data
    2. Extrae el texto del PDF directamente del archivo
    3. En paralelo:
       - Genera embeddings multi-aspecto usando IA
       - Extrae y estructura los datos del CV usando IA
    4. Guarda todo en la colecci√≥n "userCVs" de la base de datos del usuario
    
    Args:
        cv_pdf_file: Archivo PDF del CV subido como multipart/form-data
        user_id: ID del usuario como form field
        
    Returns:
        dict: Informaci√≥n del CV subido exitosamente
        {
            "success": true,
            "cv_id": "string",
            "cv_info": {
                "title": "string",
                "full_name": "string", 
                "email": "string",
                "created_at": "string",
                "template": "string"
            }
            "timing_stats": {
                "pdf_extraction": number,
                "parallel_processing": number,
                "document_preparation": number,
                "database_save": number,
                "response_preparation": number,
                "total_time": number
            }
        }
    """
    print("üöÄ POST /upload-cv")
    print(f"   - Nombre del archivo: {cv_pdf_file.filename}")
    print(f"   - Tipo de contenido: {cv_pdf_file.content_type}")
    print(f"   - User ID: {user_id}")
    
    try:
        # Validar que sea un archivo PDF
        if not cv_pdf_file.filename.lower().endswith('.pdf'):
            raise HTTPException(status_code=400, detail="El archivo debe ser un PDF")
        
        if cv_pdf_file.content_type != 'application/pdf':
            raise HTTPException(status_code=400, detail="El archivo debe ser de tipo application/pdf")
        
        # Leer el contenido del archivo
        file_content = await cv_pdf_file.read()
        print(f"   - Tama√±o del archivo: {len(file_content)} bytes")
        
        # Procesar la subida del CV
        result = await upload_cv_to_database(file_content, user_id)
        
        print(f"‚úÖ CV subido exitosamente: {result['cv_id']}")
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error en upload_cv: {e}")
        raise HTTPException(status_code=500, detail=f"Error al subir CV: {str(e)}")

# endpoint para crear un CV en la base de datos del usuario
@app.post("/cv")
async def create_cv(cv: dict):
    """
    Crea un CV a partir de un JSON con al menos 'userId' y 'data'.
    """
    result = await save_cv_service(cv)
    print(f"‚úÖ CV subido exitosamente: {result['cv_id']}")
    return result

# endpoint para actualizar un CV (el servicio maneja la l√≥gica de embeddings)
@app.put("/cv/{cv_id}")
async def update_user_cv(cv_id: str, cv: dict):
    """
    Actualiza un CV existente. 
    - El servicio detecta autom√°ticamente si el 'data' ha cambiado y recalcula embeddings
    - Si se incluyen 'embeddings', los usa directamente
    - Si solo se actualiza 'title', 'template' u otros campos, mantiene embeddings existentes
    """
    try:
        result = await update_cv_service(cv_id, cv)
        
        # Mostrar informaci√≥n sobre lo que se hizo
        if result.get("embeddings_generated"):
            if result.get("data_changed"):
                print(f"üîÑ CV actualizado con nuevos embeddings y PDF (data cambi√≥): {result['cv_id']}")
            else:
                print(f"üîç CV actualizado con nuevos embeddings (no ten√≠a): {result['cv_id']}")
        else:
            print(f"üìù CV actualizado sin regenerar embeddings: {result['cv_id']}")
        
        # Mostrar informaci√≥n sobre PDF si se gener√≥
        if result.get("pdf_generated"):
            print(f"üìÑ Nuevo PDF generado y subido: {result.get('file_url', 'N/A')}")
        
        return result
        
    except ValueError as e:
        print(f"‚ùå CV no encontrado: {cv_id}")
        raise HTTPException(status_code=404, detail=f"CV no encontrado: {str(e)}")
    except Exception as e:
        print(f"‚ùå Error en update_user_cv: {e}")
        raise HTTPException(status_code=500, detail=f"Error al actualizar CV: {str(e)}")

@app.get("/user-cvs/{user_id}")
async def list_user_cvs(user_id: str):
    """
    Obtiene todos los CVs de un usuario.
    """
    print(f"üöÄ GET /user-cvs/{user_id}")

    try:
        cvs = await get_user_cvs_service(user_id)

        print(f"‚úÖ CVs obtenidos: {len(cvs)} CVs encontrados")
        return {
            "success": True,
            "user_id": user_id,
            "total_cvs": len(cvs),
            "cvs": cvs,
        }

    except Exception as e:
        print(f"‚ùå Error en get_user_cvs: {e}")
        raise HTTPException(status_code=500, detail=f"Error al obtener CVs: {str(e)}")


@app.get("/cv/{cv_id}")
async def get_cv(cv_id: str):
    """
    Obtiene un CV espec√≠fico por su ID.
    """
    print(f"üöÄ GET /cv/{cv_id}")

    try:
        cv = await get_cv_by_id(cv_id)
        
        # Quitar los embeddings para no enviarlos al frontend
        cv["embeddings"] = None
        
        print(f"‚úÖ CV obtenido: {cv.get('title', 'Sin t√≠tulo')}")
        return cv

    except ValueError as e:
        print(f"‚ùå CV no encontrado: {cv_id}")
        raise HTTPException(status_code=404, detail=f"CV no encontrado: {str(e)}")
    except Exception as e:
        print(f"‚ùå Error en get_cv: {e}")
        raise HTTPException(status_code=500, detail=f"Error al obtener CV: {str(e)}")


@app.delete("/cv/{cv_id}")
async def delete_user_cv(cv_id: str):
    """
    Elimina un CV por `cv_id`. Si el usuario ten√≠a ese CV como seleccionado,
    se reasigna al m√°s reciente o se limpia el campo si no hay m√°s.
    """
    print(f"üöÄ DELETE /cv/{cv_id}")
    
    try:
        if not cv_id or cv_id.strip() == "":
            raise HTTPException(status_code=400, detail="cv_id es requerido y no puede estar vac√≠o")
        
        result = await delete_cv_service(cv_id)
        print(f"‚úÖ CV eliminado exitosamente: {cv_id}")
        return result
        
    except ValueError as e:
        print(f"‚ùå Error de validaci√≥n en delete_user_cv: {e}")
        raise HTTPException(status_code=404, detail=f"CV no encontrado: {str(e)}")
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error inesperado en delete_user_cv: {e}")
        import traceback
        print(f"   Stack trace: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Error interno al eliminar CV: {str(e)}")


